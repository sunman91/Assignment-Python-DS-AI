{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ===Task===\n",
    "\n",
    "Modify the above scratch code such that:\n",
    "- Notice that we are still using max_depth = 1.  Attempt to tweak min_samples_split, max_depth for the regression and see whether we can achieve better mse on our boston data\n",
    "- Notice that we only write scratch code for gradient boosting for regression, add some code so that it also works for binary classification.  Load the breast cancer data from sklearn and see that it works.\n",
    "- Further change the code so that it works for multiclass classification.  Load the digits data from sklearn and see that it works\n",
    "- Put everything into class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBoosting:\n",
    "    def __init__(self, num_stumps=5, learning_rate=1, max_depth = 1, \n",
    "                 min_samples_split = 2,\n",
    "                 classification=False):\n",
    "        self.num_stumps = num_stumps\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.classification=classification\n",
    "            \n",
    "        #initialize regression trees\n",
    "        self.model_list = [DecisionTreeRegressor(max_depth =self.max_depth,\n",
    "                                                 min_samples_split = self.min_samples_split ) for _ in range(num_stumps)]  \n",
    "        #inserting a dumb model for the first model\n",
    "        first_model = DummyRegressor(strategy='median')\n",
    "        self.model_list.insert(0, first_model)\n",
    "        \n",
    "    def grad(self, y, yhat):\n",
    "        return y - yhat\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        s = np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "        return s\n",
    "    \n",
    "    def fit(self, X_train, y_train):  #<----X_train\n",
    "        \n",
    "        #fit the first model\n",
    "        self.model_list[0].fit(X_train, y_train)\n",
    "        \n",
    "        for i in range(self.num_stumps):\n",
    "            #predict\n",
    "            yhat = self.predict(X_train, self.model_list[:i+1],\n",
    "                                with_argmax=False)\n",
    "            \n",
    "            #get the gradient\n",
    "            gradient = self.grad(y_train, yhat)\n",
    "            \n",
    "            #fit the next model with gradient\n",
    "            self.model_list[i+1].fit(X_train, gradient)\n",
    "    \n",
    "    def predict(self, X, model_list=None, with_argmax=True):\n",
    "        if model_list is None:\n",
    "            model_list = self.model_list\n",
    "            \n",
    "        h0 = model_list[0].predict(X)  #first use the dummy model\n",
    "        boosting = sum(self.learning_rate * model.predict(X) \n",
    "                       for model in model_list[1:])\n",
    "        yhat = h0 + boosting\n",
    "        \n",
    "        #for the classification part\n",
    "        if (self.classification == True):\n",
    "            \n",
    "            #turn into probability using softmax\n",
    "            yhat = self.softmax(yhat)\n",
    "            #np.exp(yhat) / np.sum(np.exp(yhat), axis=1, keepdims=True)\n",
    "            \n",
    "            if with_argmax:\n",
    "                yhat = np.argmax(yhat, axis=1)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for model 1:  12.94555760162601\n",
      "MSE for model 2:  8.287219801101964\n"
     ]
    }
   ],
   "source": [
    "# Regression\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                        test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model1 = GBoosting(num_stumps=200, learning_rate=0.1, max_depth = 1, \n",
    "                 min_samples_split = 2\n",
    "                 )\n",
    "model1.fit(X_train, y_train)\n",
    "yhat = model1.predict(X_test)\n",
    "\n",
    "#print metrics\n",
    "print(\"MSE for model 1: \", mean_squared_error(y_test, yhat))\n",
    "\n",
    "\n",
    "model2 = GBoosting(num_stumps=200, learning_rate=0.1, max_depth = 3, \n",
    "                 min_samples_split = 3\n",
    "                 )\n",
    "model2.fit(X_train, y_train)\n",
    "yhat = model2.predict(X_test)\n",
    "\n",
    "#print metrics\n",
    "print(\"MSE for model 2: \", mean_squared_error(y_test, yhat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the MSE is decreased by increasing the max depth and min_sample _split in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification accuracy:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Binary classification\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=52)\n",
    "\n",
    "#one hot encoding the y\n",
    "y_train_encoded = np.zeros((y_train.shape[0], len(set(y))))\n",
    "\n",
    "for class_col in range(len(set(y))):\n",
    "    y_train_encoded[np.where(y_train==class_col), class_col] = 1\n",
    "    \n",
    "\n",
    "model = GBoosting(num_stumps=200, learning_rate=0.1, max_depth = 3, \n",
    "                 min_samples_split = 2,\n",
    "                 classification=True)\n",
    "model.fit(X_train, y_train_encoded)\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# #print metrics\n",
    "print(\"Binary classification accuracy: \", accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass classifcation accuracy:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Multiclass classification\n",
    "\n",
    "from sklearn.datasets import load_digits \n",
    "#loading the digits database\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "\n",
    "#one hot encoding the y\n",
    "y_train_encoded = np.zeros((y_train.shape[0], len(set(y))))\n",
    "\n",
    "\n",
    "for class_col in range(len(set(y))):\n",
    "    y_train_encoded[np.where(y_train==class_col), class_col] = 1\n",
    "\n",
    "model = GBoosting(num_stumps=200, learning_rate=0.1, max_depth = 3, \n",
    "                 min_samples_split = 2,\n",
    "                 classification=True)\n",
    "model.fit(X_train, y_train_encoded)\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# #print metrics\n",
    "print(\"Multiclass classifcation accuracy: \", accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
